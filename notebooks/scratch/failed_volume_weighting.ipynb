{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Volume-Weighted DiD (FAILED)\n",
    "\n",
    "Idea: Weight observations by volume to give more importance to liquid trading days.\n",
    "\n",
    "Theory: Low volume days = noisy prices, high volume = real price discovery\n",
    "\n",
    "Spoiler: This doesn't work. Large IPOs dominate everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from linearmodels.panel import PanelOLS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('../../data/processed/stock_prices_ipo_adjusted.csv',\n",
    "                 parse_dates=['Date', 'IPO_Date'])\n",
    "\n",
    "df['Post_Lockup'] = (df['Days_Since_IPO'] > 180).astype(int)\n",
    "df_clean = df.dropna(subset=['Abnormal_Return']).copy()\n",
    "\n",
    "print(f\"Loaded {len(df_clean):,} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approach1",
   "metadata": {},
   "source": [
    "## Approach 1: Simple Volume Weights\n",
    "\n",
    "Weight = Volume / Mean(Volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "volume_weights",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize volume by ticker (different IPOs have very different volume scales)\n",
    "df_clean['Volume_Normalized'] = df_clean.groupby('Ticker')['Volume'].transform(\n",
    "    lambda x: x / x.mean()\n",
    ")\n",
    "\n",
    "# Cap at 10x to avoid extreme outliers\n",
    "df_clean['Weight'] = df_clean['Volume_Normalized'].clip(upper=10)\n",
    "\n",
    "print(f\"Weight range: {df_clean['Weight'].min():.2f} to {df_clean['Weight'].max():.2f}\")\n",
    "print(f\"Mean weight: {df_clean['Weight'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wls_regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try WLS\n",
    "df_panel = df_clean.set_index(['Ticker', 'Date'])\n",
    "\n",
    "model_wls = PanelOLS(\n",
    "    dependent=df_panel['Abnormal_Return'],\n",
    "    exog=df_panel[['Post_Lockup']],\n",
    "    weights=df_panel['Weight'],\n",
    "    entity_effects=True,\n",
    "    time_effects=True\n",
    ").fit(cov_type='clustered', cluster_entity=True)\n",
    "\n",
    "print(f\"\\nWLS Result: {model_wls.params['Post_Lockup']:.4f}%\")\n",
    "print(f\"P-value: {model_wls.pvalues['Post_Lockup']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "problem",
   "metadata": {},
   "source": [
    "## Problem: Results are all over the place\n",
    "\n",
    "Ran this 5 times with different volume normalizations:\n",
    "- Raw volume: +0.12% (p=0.67) - not significant\n",
    "- Log volume: +0.89% (p=0.001) - way too big\n",
    "- Sqrt volume: +0.31% (p=0.12) - borderline\n",
    "- Rank-based: -0.05% (p=0.85) - wtf\n",
    "\n",
    "Unweighted gives +0.45% consistently.\n",
    "\n",
    "**Diagnosis**: Large IPOs (SNOW, COIN, ABNB) have 100x volume of small ones. Even with normalization, they dominate. WLS is giving me \"large IPO effect\" not \"lockup effect\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_domination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which IPOs get highest weight\n",
    "avg_weight = df_clean.groupby('Ticker')['Weight'].mean().sort_values(ascending=False)\n",
    "print(\"Top 10 weighted IPOs:\")\n",
    "print(avg_weight.head(10))\n",
    "\n",
    "# Yeah, it's all the mega-caps\n",
    "# SNOW, COIN, ABNB, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion: Don't use volume weighting\n",
    "\n",
    "Reasons:\n",
    "1. Results unstable - changes a lot based on normalization\n",
    "2. Large IPOs dominate even after normalization  \n",
    "3. Low-volume days might actually be informative (insider trading?)\n",
    "4. Unweighted is more conservative anyway\n",
    "\n",
    "Sticking with unweighted TWFE + clustered SEs.\n",
    "\n",
    "**Time wasted**: 3 hours\n",
    "\n",
    "**Lesson learned**: Simple is better. Don't over-engineer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
